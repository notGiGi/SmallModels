{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ecfbda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELL 1: Clone Repo & Setup\n",
    "# ========================================\n",
    "!git clone https://github.com/notGiGi/SmallModels.git\n",
    "%cd SmallModels\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q lm-eval transformers accelerate datasets torch\n",
    "\n",
    "print(\"âœ“ Setup complete\")\n",
    "\n",
    "# ========================================\n",
    "# CELL 2: Check GPU\n",
    "# ========================================\n",
    "import torch\n",
    "\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\" if torch.cuda.is_available() else \"N/A\")\n",
    "\n",
    "# ========================================\n",
    "# CELL 3: Quick Test (10 samples)\n",
    "# ========================================\n",
    "from src.lm_eval_wrapper import ModelEvaluator\n",
    "\n",
    "evaluator = ModelEvaluator(device=\"cuda\", batch_size=8)\n",
    "\n",
    "results = evaluator.evaluate_model(\n",
    "    model_key=\"smollm\",\n",
    "    tasks=[\"boolq\"],\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "print(f\"Test: {results['results']['boolq']['acc,none']:.2%}\")\n",
    "\n",
    "# ========================================\n",
    "# CELL 4: Full Evaluation - SmolLM\n",
    "# ========================================\n",
    "tasks = [\"boolq\", \"hellaswag\", \"arc_easy\", \"arc_challenge\", \"winogrande\", \"piqa\"]\n",
    "\n",
    "print(\"Evaluating SmolLM (360M)...\")\n",
    "results_smollm = evaluator.evaluate_model(\n",
    "    model_key=\"smollm\",\n",
    "    tasks=tasks,\n",
    "    limit=None  # Full\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for task in tasks:\n",
    "    acc = results_smollm[\"results\"][task][\"acc,none\"]\n",
    "    print(f\"  {task:15s}: {acc:.2%}\")\n",
    "\n",
    "# Save\n",
    "from src.lm_eval_wrapper import LMEvalWrapper\n",
    "wrapper = LMEvalWrapper(\"dummy\", \"cuda\")\n",
    "wrapper.save_results(results_smollm, \"results/smollm_full.json\")\n",
    "\n",
    "# Download results\n",
    "from google.colab import files\n",
    "files.download(\"results/smollm_full.json\")\n",
    "\n",
    "# ========================================\n",
    "# CELL 5: Full Evaluation - TinyLlama\n",
    "# ========================================\n",
    "print(\"\\nEvaluating TinyLlama (1.1B)...\")\n",
    "evaluator.batch_size = 8  # Adjust for larger model\n",
    "\n",
    "results_tiny = evaluator.evaluate_model(\n",
    "    model_key=\"tinyllama\",\n",
    "    tasks=tasks,\n",
    "    limit=None\n",
    ")\n",
    "\n",
    "for task in tasks:\n",
    "    acc = results_tiny[\"results\"][task][\"acc,none\"]\n",
    "    print(f\"  {task:15s}: {acc:.2%}\")\n",
    "\n",
    "wrapper.save_results(results_tiny, \"results/tinyllama_full.json\")\n",
    "files.download(\"results/tinyllama_full.json\")\n",
    "\n",
    "# ========================================\n",
    "# CELL 6: Full Evaluation - Qwen\n",
    "# ========================================\n",
    "print(\"\\nEvaluating Qwen (1.5B)...\")\n",
    "evaluator.batch_size = 4  # Smaller batch for largest model\n",
    "\n",
    "results_qwen = evaluator.evaluate_model(\n",
    "    model_key=\"qwen\",\n",
    "    tasks=tasks,\n",
    "    limit=None\n",
    ")\n",
    "\n",
    "for task in tasks:\n",
    "    acc = results_qwen[\"results\"][task][\"acc,none\"]\n",
    "    print(f\"  {task:15s}: {acc:.2%}\")\n",
    "\n",
    "wrapper.save_results(results_qwen, \"results/qwen_full.json\")\n",
    "files.download(\"results/qwen_full.json\")\n",
    "\n",
    "# ========================================\n",
    "# CELL 7: Summary Table\n",
    "# ========================================\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "for name, results in [(\"SmolLM\", results_smollm), \n",
    "                      (\"TinyLlama\", results_tiny), \n",
    "                      (\"Qwen\", results_qwen)]:\n",
    "    row = {\"Model\": name}\n",
    "    for task in tasks:\n",
    "        acc = results[\"results\"][task][\"acc,none\"]\n",
    "        row[task] = f\"{acc:.2%}\"\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
